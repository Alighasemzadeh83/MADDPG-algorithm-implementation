{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElBHawv1yleL",
        "outputId": "912c3adf-ed4e-4d8c-bcea-d19ba3b60b15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'multiagent-particle-envs' already exists and is not an empty directory.\n",
            "fatal: destination path 'maddpg-pytorch' already exists and is not an empty directory.\n",
            "fatal: destination path 'auto_LiRPA' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# cloning repositories\n",
        "!git clone https://github.com/openai/multiagent-particle-envs.git\n",
        "!git clone https://github.com/shariqiqbal2810/maddpg-pytorch.git\n",
        "!git clone https://github.com/Verified-Intelligence/auto_LiRPA.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd multiagent-particle-envs\n",
        "!pip install -e .\n",
        "%cd ..\n",
        "\n",
        "%cd maddpg-pytorch\n",
        "!pip install torch==0.3.0.post4 gym==0.10.5 tensorboard==0.4.0rc3 tensorboardX==1.0\n",
        "%cd ..\n",
        "\n",
        "%cd auto_LiRPA\n",
        "!pip install -e .\n",
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qkq39QAy2EU",
        "outputId": "18a965fc-b08f-4c29-8640-f3435ae41f0f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multiagent-particle-envs\n",
            "Obtaining file:///content/multiagent-particle-envs\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (from multiagent==0.0.1) (0.10.5)\n",
            "Requirement already satisfied: numpy-stl in /usr/local/lib/python3.11/dist-packages (from multiagent==0.0.1) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.11/dist-packages (from gym->multiagent==0.0.1) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.11/dist-packages (from gym->multiagent==0.0.1) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from gym->multiagent==0.0.1) (1.17.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym->multiagent==0.0.1) (2.1.2)\n",
            "Requirement already satisfied: python-utils>=3.4.5 in /usr/local/lib/python3.11/dist-packages (from numpy-stl->multiagent==0.0.1) (3.9.1)\n",
            "Requirement already satisfied: typing_extensions>3.10.0.2 in /usr/local/lib/python3.11/dist-packages (from python-utils>=3.4.5->numpy-stl->multiagent==0.0.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->gym->multiagent==0.0.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->gym->multiagent==0.0.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->gym->multiagent==0.0.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->gym->multiagent==0.0.1) (2024.12.14)\n",
            "Installing collected packages: multiagent\n",
            "  Attempting uninstall: multiagent\n",
            "    Found existing installation: multiagent 0.0.1\n",
            "    Uninstalling multiagent-0.0.1:\n",
            "      Successfully uninstalled multiagent-0.0.1\n",
            "  Running setup.py develop for multiagent\n",
            "Successfully installed multiagent-0.0.1\n",
            "/content\n",
            "/content/maddpg-pytorch\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==0.3.0.post4 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==0.3.0.post4\u001b[0m\u001b[31m\n",
            "\u001b[0m/content\n",
            "/content/auto_LiRPA\n",
            "Obtaining file:///content/auto_LiRPA\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch<2.4.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (2.3.1)\n",
            "Requirement already satisfied: torchvision<0.19.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (0.18.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (24.2)\n",
            "Requirement already satisfied: pytest==8.1.1 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (8.1.1)\n",
            "Requirement already satisfied: pylint>=2.15 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (3.3.4)\n",
            "Requirement already satisfied: pytest-order>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (1.3.0)\n",
            "Requirement already satisfied: pytest-mock>=3.14 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (3.14.0)\n",
            "Requirement already satisfied: appdirs>=1.4 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (1.4.4)\n",
            "Requirement already satisfied: pyyaml>=5.0 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (6.0.2)\n",
            "Requirement already satisfied: ninja<1.11.1.2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (1.11.1.1)\n",
            "Requirement already satisfied: tqdm>=4.64 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: graphviz>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from auto_LiRPA==0.6.0) (0.20.3)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest==8.1.1->auto_LiRPA==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from pytest==8.1.1->auto_LiRPA==0.6.0) (1.5.0)\n",
            "Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from pylint>=2.15->auto_LiRPA==0.6.0) (0.3.9)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pylint>=2.15->auto_LiRPA==0.6.0) (4.3.6)\n",
            "Requirement already satisfied: astroid<=3.4.0-dev0,>=3.3.8 in /usr/local/lib/python3.11/dist-packages (from pylint>=2.15->auto_LiRPA==0.6.0) (3.3.8)\n",
            "Requirement already satisfied: isort!=5.13.0,<7,>=4.2.5 in /usr/local/lib/python3.11/dist-packages (from pylint>=2.15->auto_LiRPA==0.6.0) (6.0.0)\n",
            "Requirement already satisfied: mccabe<0.8,>=0.6 in /usr/local/lib/python3.11/dist-packages (from pylint>=2.15->auto_LiRPA==0.6.0) (0.7.0)\n",
            "Requirement already satisfied: tomlkit>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from pylint>=2.15->auto_LiRPA==0.6.0) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (12.5.82)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision<0.19.0,>=0.12.0->auto_LiRPA==0.6.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.4.0,>=2.0.0->auto_LiRPA==0.6.0) (1.3.0)\n",
            "Installing collected packages: auto_LiRPA\n",
            "  Attempting uninstall: auto_LiRPA\n",
            "    Found existing installation: auto_LiRPA 0.6.0\n",
            "    Uninstalling auto_LiRPA-0.6.0:\n",
            "      Successfully uninstalled auto_LiRPA-0.6.0\n",
            "  Running setup.py develop for auto_LiRPA\n",
            "Successfully installed auto_LiRPA-0.6.0\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall gym\n",
        "!pip install gym==0.10.5\n",
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "vq2RMup30nkE",
        "outputId": "2250819d-7dc5-409a-d424-b2f34de42c40"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gym 0.10.5\n",
            "Uninstalling gym-0.10.5:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/gym-0.10.5.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/gym/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled gym-0.10.5\n",
            "Collecting gym==0.10.5\n",
            "  Using cached gym-0.10.5-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.11/dist-packages (from gym==0.10.5) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.11/dist-packages (from gym==0.10.5) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from gym==0.10.5) (1.17.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym==0.10.5) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->gym==0.10.5) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->gym==0.10.5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->gym==0.10.5) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0->gym==0.10.5) (2024.12.14)\n",
            "Installing collected packages: gym\n",
            "Successfully installed gym-0.10.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDrive2ImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _PyDriveImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _GenerativeAIImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _OpenCVImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: APICoreClientInfoImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _BokehImportHook.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:1047: ImportWarning: _AltairImportHook.find_spec() not found; falling back to find_module()\n",
            "/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py:86: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.11/dist-packages/gym-0.10.5.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              },
              "id": "7227bace012b49269190bc84ed808fa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.11/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (4.25.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path\n",
        "sys.path.append('/content/multiagent-particle-envs')\n",
        "# sys.path.append('/content/maddpg-pytorch/')\n",
        "# sys.path.append('/content/auto_LiRPA')"
      ],
      "metadata": {
        "id": "DyPVOQXP1KRW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gym\n",
        "import tensorboardX\n",
        "from multiagent.environment import MultiAgentEnv\n",
        "from make_env import make_env\n",
        "import multiagent.scenarios as scenarios\n",
        "import auto_LiRPA\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "# from auto_LiRPA import BoundedModule, BoundedTensor\n",
        "# from auto_LiRPA.perturbations import *\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "gE_G_7CWzQvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c7fb0a-ed79-4c1c-b852-a3d88feb8c8a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scenario = scenarios.load('simple_spread.py').Scenario()\n",
        "world = scenario.make_world()\n",
        "env = MultiAgentEnv(world, scenario.reset_world, scenario.reward, scenario.observation)\n",
        "observations = env.reset()\n",
        "num_agents = env.n\n",
        "print(num_agents)\n",
        "env = MultiAgentEnv(world, scenario.reset_world, scenario.reward, scenario.observation, info_callback=None, shared_viewer = False)\n",
        "# env.render()\n"
      ],
      "metadata": {
        "id": "10ZH7V560U4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0416e84f-8196-42e2-ccc7-fda1c10c2286"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = make_env('simple_adversary')\n",
        "print('number of agents : ', env.n)\n",
        "print('observation space : ', env.observation_space)\n",
        "print('action space : ', env.action_space)\n",
        "print('n actions : ', env.action_space[0].n)"
      ],
      "metadata": {
        "id": "eC5J_FV-mTeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd26ed9-ab39-4531-d6c1-eee9fe422887"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of agents :  3\n",
            "observation space :  [Box(8,), Box(10,), Box(10,)]\n",
            "action space :  [Discrete(5), Discrete(5), Discrete(5)]\n",
            "n actions :  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "observation = env.reset()\n",
        "print(observation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BwOJ4-PapZK",
        "outputId": "34251b6f-8278-45f5-aa73-557b33fdeab0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([-0.68224199,  0.72622355, -0.93610742, -0.44377208, -1.62863369,\n",
            "        1.0841574 , -0.0725658 , -0.44851313]), array([ 0.9463917 , -0.35793384,  0.9463917 , -0.35793384,  0.69252627,\n",
            "       -1.52792948,  1.62863369, -1.0841574 ,  1.55606789, -1.53267052]), array([-0.60967619,  1.17473668, -0.60967619,  1.17473668, -0.86354162,\n",
            "        0.00474105,  0.0725658 ,  0.44851313, -1.55606789,  1.53267052])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_op = np.array([1, 0, 0, 0, 0])\n",
        "action = [no_op, no_op, no_op]\n",
        "obs_, reward, done, info = env.step(action)\n",
        "print(reward)\n",
        "print(obs_)\n",
        "print(done)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_ZkDuNubnEi",
        "outputId": "8b6dccb4-cd35-40cb-ed91-e9594203e42a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.9928547841100239, -0.015396136395732785, -0.015396136395732785]\n",
            "[array([-0.68224199,  0.72622355, -0.93610742, -0.44377208, -1.62863369,\n",
            "        1.0841574 , -0.0725658 , -0.44851313]), array([ 0.9463917 , -0.35793384,  0.9463917 , -0.35793384,  0.69252627,\n",
            "       -1.52792948,  1.62863369, -1.0841574 ,  1.55606789, -1.53267052]), array([-0.60967619,  1.17473668, -0.60967619,  1.17473668, -0.86354162,\n",
            "        0.00474105,  0.0725658 ,  0.44851313, -1.55606789,  1.53267052])]\n",
            "[False, False, False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_op = np.array([0, 0.1, 0.12, 0.33, 0.54])\n",
        "action = [no_op, no_op, no_op]\n",
        "obs_, reward, done, info = env.step(action)\n",
        "print(reward)\n",
        "print(obs_)\n",
        "print(done)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zifJJAqjdbTA",
        "outputId": "ffea0a38-3838-40c5-80b6-e0d91fcc2358"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.0068522447714578, -0.005669075959940484, -0.005669075959940484]\n",
            "[array([-0.68124199,  0.73672355, -0.93510742, -0.43327208, -1.62863369,\n",
            "        1.0841574 , -0.0725658 , -0.44851313]), array([ 0.9473917 , -0.34743384,  0.9473917 , -0.34743384,  0.69352627,\n",
            "       -1.51742948,  1.62863369, -1.0841574 ,  1.55606789, -1.53267052]), array([-0.60867619,  1.18523668, -0.60867619,  1.18523668, -0.86254162,\n",
            "        0.01524105,  0.0725658 ,  0.44851313, -1.55606789,  1.53267052])]\n",
            "[False, False, False]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### part 2"
      ],
      "metadata": {
        "id": "nC72gxtefO4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiAgentReplayBuffer:\n",
        "  def __init__(self, max_size, critic_dims, actor_dims,\n",
        "               n_actions, n_agents, batch_size) -> None:\n",
        "    self.mem_size = max_size\n",
        "    self.mem_cntr = 0\n",
        "    self.n_agents = n_agents\n",
        "    self.actor_dims = actor_dims\n",
        "    self.critic_dims = critic_dims\n",
        "    self.batch_size = batch_size\n",
        "    self.n_actions = n_actions\n",
        "\n",
        "    self.state_memory = np.zeros((self.mem_size, critic_dims))\n",
        "    self.new_state_memory = np.zeros((self.mem_size, critic_dims))\n",
        "    self.reward_memory = np.zeros((self.mem_size, n_agents))\n",
        "    self.terminal_memory = np.zeros((self.mem_size, n_agents), dtype=bool)\n",
        "\n",
        "    self.init_actor_memory()\n",
        "\n",
        "  def init_actor_memory(self):\n",
        "    self.actor_state_memory = []\n",
        "    self.actor_new_state_memory = []\n",
        "    self.actor_action_memory = []\n",
        "\n",
        "    for i in range(self.n_agents):\n",
        "      self.actor_state_memory.append(np.zeros((self.mem_size, self.actor_dims[i])))\n",
        "      self.actor_new_state_memory.append(np.zeros((self.mem_size, self.actor_dims[i])))\n",
        "      self.actor_action_memory.append(np.zeros((self.mem_size, self.n_actions)))\n",
        "\n",
        "  def store_transition(self, raw_obs, state, action, reward,\n",
        "                       raw_obs_, state_, done):\n",
        "    if self.mem_cntr % self.mem_size == 0 and self.mem_cntr > 0:\n",
        "      self.init_actor_memory()\n",
        "\n",
        "    index = self.mem_cntr % self.mem_size\n",
        "\n",
        "    for agent_idx in range(self.n_agents):\n",
        "      self.actor_state_memory[agent_idx][index] = raw_obs[agent_idx]\n",
        "      self.actor_new_state_memory[agent_idx][index] = raw_obs_[agent_idx]\n",
        "      self.actor_action_memory[agent_idx][index] = action[agent_idx]\n",
        "\n",
        "    self.state_memory[index] = state\n",
        "    self.new_state_memory[index] = state_\n",
        "    self.reward_memory[index] = reward\n",
        "    self.terminal_memory[index] = done\n",
        "\n",
        "    self.mem_cntr += 1\n",
        "\n",
        "  def sample_buffer(self):\n",
        "    max_mem = min(self.mem_cntr, self.mem_size)\n",
        "\n",
        "    batch = np.random.choice(max_mem, self.batch_size, replace=False)\n",
        "\n",
        "    states = self.state_memory[batch]\n",
        "    states_ = self.new_state_memory[batch]\n",
        "    rewards = self.reward_memory[batch]\n",
        "    terminal = self.terminal_memory[batch]\n",
        "\n",
        "    actor_states = []\n",
        "    actor_new_states = []\n",
        "    actions = []\n",
        "\n",
        "    for agent_idx in range(self.n_agents):\n",
        "      actor_states.append(self.actor_state_memory[agent_idx][batch])\n",
        "      actor_new_states.append(self.actor_new_state_memory[agent_idx][batch])\n",
        "      actions.append(self.actor_action_memory[agent_idx][batch])\n",
        "\n",
        "    return actor_states, states, actions, rewards, actor_new_states, states_, terminal\n",
        "\n",
        "  def ready(self):\n",
        "    if self.mem_cntr >= self.batch_size:\n",
        "      return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "8Fs1O-pneGex"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CriticNetwork(nn.Module):\n",
        "  def __init__(self, beta, input_dims, fc1_dims, fc2_dims,\n",
        "               n_agents, n_actions, name, chkpt_dir):\n",
        "    super(CriticNetwork, self).__init__()\n",
        "\n",
        "    self.chkpt_file = os.path.join(chkpt_dir, name)\n",
        "\n",
        "    self.fc1 = nn.Linear(input_dims + n_agents* n_actions, fc1_dims)\n",
        "    self.fc2 = nn.Linear(fc1_dims, fc2_dims)\n",
        "    self.q = nn.Linear(fc2_dims, 1)\n",
        "\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=beta)\n",
        "    self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    self.to(self.device)\n",
        "  def forward(self, state, action):\n",
        "    x = F.relu(self.fc1(torch.cat([state, action], dim=1)))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    q = self.q(x)\n",
        "\n",
        "    return q\n",
        "\n",
        "  def save_checkpoint(self):\n",
        "    torch.save(self.state_dict(), self.chkpt_file)\n",
        "\n",
        "  def load_checkpoint(self):\n",
        "    self.load_state_dict(torch.load(self.chkpt_file))"
      ],
      "metadata": {
        "id": "tH8F_wo7fa7y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ActorNetwork(nn.Module):\n",
        "  def __init__(self, alpha, input_dims, fc1_dims, fc2_dims,\n",
        "               n_actions, name, chkpt_dir):\n",
        "    super(ActorNetwork, self).__init__()\n",
        "\n",
        "    self.chkpt_file = os.path.join(chkpt_dir, name)\n",
        "\n",
        "    self.fc1 = nn.Linear(input_dims, fc1_dims)\n",
        "    self.fc2 = nn.Linear(fc1_dims, fc2_dims)\n",
        "    self.pi = nn.Linear(fc2_dims, n_actions)\n",
        "\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
        "    self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    self.to(self.device)\n",
        "\n",
        "  def forward(self, state):\n",
        "    x = F.relu(self.fc1(state))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    pi = torch.softmax(self.pi(x), dim=1)\n",
        "\n",
        "    return pi\n",
        "\n",
        "  def save_checkpoint(self):\n",
        "    torch.save(self.state_dict(), self.chkpt_file)\n",
        "\n",
        "  def load_checkpoint(self):\n",
        "    self.load_state_dict(torch.load(self.chkpt_file))"
      ],
      "metadata": {
        "id": "7UNDBsUErN_l"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "  def __init__(self, actor_dims, critic_dims, n_actors, agent_idx, chkpt_dir,\n",
        "               alpha=0.1, beta=0.01, fc1=64, fc2=64, gamma=0.95, tau=0.01):\n",
        "    self.gamma = gamma\n",
        "    self.tau = tau\n",
        "    self.n_actions = n_actions\n",
        "    self.agent_name = 'agent_%s' % agent_idx\n",
        "    self.actor = ActorNetwork(alpha, actor_dims, fc1, fc2, n_actions, chkpt_dir=chkpt_dir, name=self.agent_name+'_actor')\n",
        "    self.critic = CriticNetwork(beta, critic_dims, fc1, fc2, n_agents, n_actions, chkpt_dir=chkpt_dir, name=self.agent_name+'_critic')\n",
        "\n",
        "\n",
        "    self.target_actor = ActorNetwork(alpha, actor_dims, fc1, fc2, n_actions, chkpt_dir=chkpt_dir, name=self.agent_name+'_target_actor')\n",
        "    self.target_critic = CriticNetwork(beta, critic_dims, fc1, fc2, n_agents, n_actions, chkpt_dir=chkpt_dir, name=self.agent_name+'_target_critic')\n",
        "\n",
        "    self.update_network_parameters(tau=1)\n",
        "\n",
        "  def update_network_parameters(self, tau=None):\n",
        "    if tau is None:\n",
        "      tau = self.tau\n",
        "\n",
        "    target_actor_params = self.target_actor.named_parameters()\n",
        "    actor_params = self.actor.named_parameters()\n",
        "\n",
        "    target_actor_state_dict = dict(target_actor_params)\n",
        "    actor_state_dict = dict(actor_params)\n",
        "\n",
        "    for name in actor_state_dict:\n",
        "      actor_state_dict[name] = tau*actor_state_dict[name].clone() + (1-tau)*target_actor_state_dict[name].clone()\n",
        "\n",
        "    self.target_actor.load_state_dict(actor_state_dict)\n",
        "\n",
        "    target_critic_params = self.target_critic.named_parameters()\n",
        "    critic_params = self.critic.named_parameters()\n",
        "\n",
        "    target_critic_state_dict = dict(target_critic_params)\n",
        "    critic_state_dict = dict(critic_params)\n",
        "\n",
        "    for name in critic_state_dict:\n",
        "      critic_state_dict[name] = tau*critic_state_dict[name].clone() + (1-tau)*target_critic_state_dict[name].clone()\n",
        "\n",
        "    self.target_critic.load_state_dict(critic_state_dict)\n",
        "\n",
        "  def choose_action(self, observation):\n",
        "    state = torch.tensor([observation], dtype=torch.float).to(self.actor.device)\n",
        "    actions = self.actor.forward(state)\n",
        "    noise = torch.rand(self.n_actions).to(self.actor.device)\n",
        "    actions = actions + noise\n",
        "\n",
        "    return actions.detach().cpu().numpy()[0]\n",
        "\n",
        "  def save_models(self):\n",
        "    self.actor.save_checkpoint()\n",
        "    self.target_save.save_checkpoint()\n",
        "    self.critic.save_checkpoint()\n",
        "    self.target_critic.save_checkpoint()\n",
        "\n",
        "  def load_models(self):\n",
        "    self.actor.load_checkpoint()\n",
        "    self.target_actor.load_checkpoint()\n",
        "    self.critic.load_checkpoint()\n",
        "    self.target_critic.load_checkpoint()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjkhnGxNrOWv",
        "outputId": "ae45a0cc-3fa9-4315-f38b-13b11bf85d13"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MADDPG:\n",
        "  def __init__(self, actor_dims, critic_dims, n_agents, n_actions,\n",
        "               scenario='simple', alpha=0.01, beta=0.01, fc1=64, fc2=64,\n",
        "               gamma=0.99, tau=0.01, chkpt_dir='tmp/paddpg'):\n",
        "    self.agents = []\n",
        "    self.n_agents = n_agents\n",
        "    self.n_actions = n_actions\n",
        "    chkpt_dir += scenario\n",
        "\n",
        "    for agent_idx in range(self.n_agents):\n",
        "      self.agents.append(Agent(actor_dims[agent_idx], critic_dims,\n",
        "        n_actions, agent_idx, alpha=alpha, beta=beta, chkpt_dir=chkpt_dir))\n",
        "\n",
        "\n",
        "  def save_checkpoint(self):\n",
        "    print('... saving checkpoint ...')\n",
        "    for agent in self.agents:\n",
        "      agent.save_models()\n",
        "\n",
        "  def load_checkpoint(self):\n",
        "    print('... loading checkpoint ...')\n",
        "    for agent in self.agents:\n",
        "      agent.load_models()\n",
        "\n",
        "\n",
        "  def choose_action(self, raw_obs):\n",
        "    actions = []\n",
        "    for agent_idx, agent in enumerate(self.agents):\n",
        "      action = agent.choose_action(raw_obs[agent_idx])\n",
        "      actions.append(action)\n",
        "\n",
        "    return actions\n",
        "\n",
        "  def learn(self, memory):\n",
        "    if not memory.ready():\n",
        "      return\n",
        "\n",
        "    actor_states, states, actions, rewards, actor_new_states, states_, dones = memory.sample_buffer()\n",
        "\n",
        "    device = self.agents[0].actor.device\n",
        "\n",
        "    states = torch.tensor(states, dtype=torch.float).to(device)\n",
        "    states_ = torch.tensor(states_, dtype=torch.float).to(device)\n",
        "    actions = torch.tensor(actions, dtype=torch.float).to(device)\n",
        "    rewards = torch.tensor(rewards, dtype=torch.float).to(device)\n",
        "    dones = torch.tensor(dones).to(device)\n",
        "\n",
        "    all_agents_new_actions = []\n",
        "    all_agents_new_mu_actions = []\n",
        "    old_agents_actions = []\n",
        "\n",
        "    for agent_idx, agent in enumerate(self.agents):\n",
        "      new_states = torch.tensor(actor_new_states[agent_idx], dtype=torch.float).to(device)\n",
        "      new_pi = agent.target_actor.forward(new_states)\n",
        "      all_agents_new_actions.append(new_pi)\n",
        "      mu_states = torch.tensor(actor_states[agent_idx], dtype=torch.float).to(device)\n",
        "      mu_pi = agent.actor.forward(mu_states)\n",
        "      all_agents_new_mu_actions.append(mu_pi)\n",
        "      old_agents_actions.append(actions[agent_idx])\n",
        "\n",
        "    new_actions = torch.cat([acts for acts in all_agents_new_actions], dim=1)\n",
        "    mu = torch.cat([acts for acts in all_agents_new_mu_actions], dim=1)\n",
        "    old_actions = torch.cat([acts for acts in old_agents_actions], dim=1)\n",
        "\n",
        "    for agent_idx, agent in enumerate(self.agents):\n",
        "      critic_value_ = agent.target_critic.forward(states_, new_actions).flatten()\n",
        "      critic_value_[dones[:, 0]] = 0.0\n",
        "      critic_value = agent.critic.forward(states, old_actions).flatten()\n",
        "\n",
        "      target = rewards[:, agent_idx] + agent.gamma*critic_value_\n",
        "      critic_loss = F.mse_loss(target, critic_value)\n",
        "      agent.critic.optimizer.zero_grad()\n",
        "      critic_loss.backward(retain_graph=True)\n",
        "      agent.critic.optimizer.step()\n",
        "\n",
        "      actor_loss = agent.critic.forward(states, mu).flatten()\n",
        "      actor_loss = -torch.mean(actor_loss)\n",
        "      agent.actor.optimizer.zero_grad()\n",
        "      actor_loss.backward(retain_graph=True)\n",
        "      agent.actor.optimizer.step()\n",
        "\n",
        "      agent.update_network_parameters()\n",
        "\n",
        "def obs_list_to_state_vector(observation):\n",
        "  state = np.array([])\n",
        "  for obs in observation:\n",
        "    state = np.concatenate([state, obs])\n",
        "  return state\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsZAitxhvCI5",
        "outputId": "f398780e-874c-41fd-c8a5-a2b84822f72e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  scenario = 'simple'\n",
        "  env = make_env(scenario)\n",
        "  n_agents = env.n\n",
        "  actor_dims = []\n",
        "  for i in range(n_agents):\n",
        "    actor_dims.append(env.observation_space[i].shape[0])\n",
        "\n",
        "  critic_dims = sum(actor_dims)\n",
        "\n",
        "  n_actions = env.action_space[0].n\n",
        "  maddpg_agents = MADDPG(actor_dims, critic_dims, n_agents, n_actions,\n",
        "                         fc1=64, fc2=64, alpha=0.01, beta=0.01, scenario=scenario,\n",
        "                         chkpt_dir='tmp/maddpg')\n",
        "  memory = MultiAgentReplayBuffer(1000000, critic_dims, actor_dims,\n",
        "                                  n_actions, n_agents, batch_size=1024)\n",
        "  PRINT_INTERVAL = 500\n",
        "  N_GAMES = 30000\n",
        "  MAX_STEPS = 25\n",
        "  total_steps = 0\n",
        "  score_history = []\n",
        "  evaluate = False\n",
        "  best_score = 0\n",
        "\n",
        "  if evaluate:\n",
        "    maddpg_agents.load_checkpoint()\n",
        "\n",
        "  for i in range(N_GAMES):\n",
        "    obs = env.reset()\n",
        "    score = 0\n",
        "    done = [False for _ in range(n_agents)]\n",
        "    episode_step = 0\n",
        "    while not any(done):\n",
        "      if evaluate:\n",
        "        env.render()\n",
        "      actions = maddpg_agents.choose_action(obs)\n",
        "      obs_, reward, done, info = env.step(actions)\n",
        "\n",
        "      state = obs_list_to_state_vector(obs)\n",
        "      state_ = obs_list_to_state_vector(obs_)\n",
        "\n",
        "      if episode_step > MAX_STEPS:\n",
        "        done = [True]*n_agents\n",
        "\n",
        "      memory.store_transition(obs, state, actions, reward, obs_, state_, done)\n",
        "\n",
        "      if total_steps % 100 == 0 and not evaluate:\n",
        "        maddpg_agents.learn(memory)\n",
        "\n",
        "      obs = obs_\n",
        "      score += sum(reward)\n",
        "      total_steps += 1\n",
        "      episode_step += 1\n",
        "\n",
        "      score_history.append(score)\n",
        "\n",
        "      avg_score = np.mean(score_history[-100:])\n",
        "      if not evaluate:\n",
        "        if avg_score > best_score:\n",
        "          maddpg_agents.save_checkpoint()\n",
        "          best_score = avg_score\n",
        "\n",
        "      if i % PRINT_INTERVAL == 0 and i > 0:\n",
        "        print('episode', i, 'average score{:.1f}'.format(avg_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfBLcdVdz0GC",
        "outputId": "f918c6ba-f137-46d2-91b3-eb7ac7d9ffde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode 500 average score-3.2\n",
            "episode 500 average score-3.2\n",
            "episode 500 average score-3.2\n",
            "episode 500 average score-3.3\n",
            "episode 500 average score-3.3\n",
            "episode 500 average score-3.4\n",
            "episode 500 average score-3.4\n",
            "episode 500 average score-3.5\n",
            "episode 500 average score-3.5\n",
            "episode 500 average score-3.6\n",
            "episode 500 average score-3.7\n",
            "episode 500 average score-3.7\n",
            "episode 500 average score-3.8\n",
            "episode 500 average score-3.9\n",
            "episode 500 average score-3.9\n",
            "episode 500 average score-4.0\n",
            "episode 500 average score-4.1\n",
            "episode 500 average score-4.2\n",
            "episode 500 average score-4.3\n",
            "episode 500 average score-4.4\n",
            "episode 500 average score-4.6\n",
            "episode 500 average score-4.8\n",
            "episode 500 average score-4.9\n",
            "episode 500 average score-5.1\n",
            "episode 500 average score-5.2\n",
            "episode 500 average score-5.4\n",
            "episode 500 average score-5.6\n",
            "episode 1000 average score-4.9\n",
            "episode 1000 average score-4.8\n",
            "episode 1000 average score-4.7\n",
            "episode 1000 average score-4.6\n",
            "episode 1000 average score-4.4\n",
            "episode 1000 average score-4.3\n",
            "episode 1000 average score-4.2\n",
            "episode 1000 average score-4.1\n",
            "episode 1000 average score-3.9\n",
            "episode 1000 average score-3.8\n",
            "episode 1000 average score-3.7\n",
            "episode 1000 average score-3.5\n",
            "episode 1000 average score-3.4\n",
            "episode 1000 average score-3.2\n",
            "episode 1000 average score-3.1\n",
            "episode 1000 average score-3.0\n",
            "episode 1000 average score-2.8\n",
            "episode 1000 average score-2.7\n",
            "episode 1000 average score-2.5\n",
            "episode 1000 average score-2.5\n",
            "episode 1000 average score-2.5\n",
            "episode 1000 average score-2.6\n",
            "episode 1000 average score-2.6\n",
            "episode 1000 average score-2.5\n",
            "episode 1000 average score-2.5\n",
            "episode 1000 average score-2.5\n",
            "episode 1000 average score-2.5\n",
            "episode 1500 average score-5.4\n",
            "episode 1500 average score-5.4\n",
            "episode 1500 average score-5.4\n",
            "episode 1500 average score-5.5\n",
            "episode 1500 average score-5.5\n",
            "episode 1500 average score-5.6\n",
            "episode 1500 average score-5.6\n",
            "episode 1500 average score-5.7\n",
            "episode 1500 average score-5.7\n",
            "episode 1500 average score-5.8\n",
            "episode 1500 average score-5.9\n",
            "episode 1500 average score-5.9\n",
            "episode 1500 average score-6.0\n",
            "episode 1500 average score-6.1\n",
            "episode 1500 average score-6.2\n",
            "episode 1500 average score-6.2\n",
            "episode 1500 average score-6.3\n",
            "episode 1500 average score-6.4\n",
            "episode 1500 average score-6.5\n",
            "episode 1500 average score-6.6\n",
            "episode 1500 average score-6.6\n",
            "episode 1500 average score-6.7\n",
            "episode 1500 average score-6.8\n",
            "episode 1500 average score-6.8\n",
            "episode 1500 average score-6.9\n",
            "episode 1500 average score-7.0\n",
            "episode 1500 average score-7.0\n",
            "episode 2000 average score-5.7\n",
            "episode 2000 average score-5.5\n",
            "episode 2000 average score-5.4\n",
            "episode 2000 average score-5.3\n",
            "episode 2000 average score-5.1\n",
            "episode 2000 average score-4.9\n",
            "episode 2000 average score-4.8\n",
            "episode 2000 average score-4.6\n",
            "episode 2000 average score-4.5\n",
            "episode 2000 average score-4.3\n",
            "episode 2000 average score-4.1\n",
            "episode 2000 average score-3.9\n",
            "episode 2000 average score-3.8\n",
            "episode 2000 average score-3.6\n",
            "episode 2000 average score-3.4\n",
            "episode 2000 average score-3.3\n",
            "episode 2000 average score-3.1\n",
            "episode 2000 average score-2.9\n",
            "episode 2000 average score-2.7\n",
            "episode 2000 average score-2.8\n",
            "episode 2000 average score-2.8\n",
            "episode 2000 average score-2.8\n",
            "episode 2000 average score-2.8\n",
            "episode 2000 average score-2.8\n",
            "episode 2000 average score-2.9\n",
            "episode 2000 average score-2.9\n",
            "episode 2000 average score-2.9\n",
            "episode 2500 average score-2.4\n",
            "episode 2500 average score-2.4\n",
            "episode 2500 average score-2.4\n",
            "episode 2500 average score-2.4\n",
            "episode 2500 average score-2.4\n",
            "episode 2500 average score-2.4\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.3\n",
            "episode 2500 average score-2.4\n",
            "episode 2500 average score-2.5\n",
            "episode 2500 average score-2.5\n",
            "episode 2500 average score-2.6\n",
            "episode 2500 average score-2.6\n",
            "episode 2500 average score-2.7\n",
            "episode 2500 average score-2.8\n",
            "episode 2500 average score-2.8\n",
            "episode 3000 average score-5.1\n",
            "episode 3000 average score-5.1\n",
            "episode 3000 average score-5.1\n",
            "episode 3000 average score-5.1\n",
            "episode 3000 average score-5.2\n",
            "episode 3000 average score-5.2\n",
            "episode 3000 average score-5.2\n",
            "episode 3000 average score-5.3\n",
            "episode 3000 average score-5.3\n",
            "episode 3000 average score-5.4\n",
            "episode 3000 average score-5.5\n",
            "episode 3000 average score-5.5\n",
            "episode 3000 average score-5.6\n",
            "episode 3000 average score-5.6\n",
            "episode 3000 average score-5.7\n",
            "episode 3000 average score-5.8\n",
            "episode 3000 average score-5.8\n",
            "episode 3000 average score-5.9\n",
            "episode 3000 average score-6.0\n",
            "episode 3000 average score-6.1\n",
            "episode 3000 average score-6.2\n",
            "episode 3000 average score-6.3\n",
            "episode 3000 average score-6.3\n",
            "episode 3000 average score-6.4\n",
            "episode 3000 average score-6.5\n",
            "episode 3000 average score-6.6\n",
            "episode 3000 average score-6.7\n",
            "episode 3500 average score-6.0\n",
            "episode 3500 average score-6.0\n",
            "episode 3500 average score-6.0\n",
            "episode 3500 average score-6.0\n",
            "episode 3500 average score-6.1\n",
            "episode 3500 average score-6.1\n",
            "episode 3500 average score-6.2\n",
            "episode 3500 average score-6.2\n",
            "episode 3500 average score-6.3\n",
            "episode 3500 average score-6.4\n",
            "episode 3500 average score-6.4\n",
            "episode 3500 average score-6.5\n",
            "episode 3500 average score-6.6\n",
            "episode 3500 average score-6.7\n",
            "episode 3500 average score-6.8\n",
            "episode 3500 average score-6.9\n",
            "episode 3500 average score-7.0\n",
            "episode 3500 average score-7.0\n",
            "episode 3500 average score-7.1\n",
            "episode 3500 average score-7.3\n",
            "episode 3500 average score-7.4\n",
            "episode 3500 average score-7.5\n",
            "episode 3500 average score-7.6\n",
            "episode 3500 average score-7.7\n",
            "episode 3500 average score-7.8\n",
            "episode 3500 average score-7.9\n",
            "episode 3500 average score-7.9\n",
            "episode 4000 average score-7.8\n",
            "episode 4000 average score-7.8\n",
            "episode 4000 average score-7.9\n",
            "episode 4000 average score-8.0\n",
            "episode 4000 average score-8.0\n",
            "episode 4000 average score-8.1\n",
            "episode 4000 average score-8.2\n",
            "episode 4000 average score-8.3\n",
            "episode 4000 average score-8.4\n",
            "episode 4000 average score-8.5\n",
            "episode 4000 average score-8.6\n",
            "episode 4000 average score-8.7\n",
            "episode 4000 average score-8.8\n",
            "episode 4000 average score-8.9\n",
            "episode 4000 average score-9.0\n",
            "episode 4000 average score-9.1\n",
            "episode 4000 average score-9.2\n",
            "episode 4000 average score-9.3\n",
            "episode 4000 average score-9.4\n",
            "episode 4000 average score-9.5\n",
            "episode 4000 average score-9.6\n",
            "episode 4000 average score-9.7\n",
            "episode 4000 average score-9.9\n",
            "episode 4000 average score-10.0\n",
            "episode 4000 average score-10.1\n",
            "episode 4000 average score-10.2\n",
            "episode 4000 average score-10.3\n",
            "episode 4500 average score-6.3\n",
            "episode 4500 average score-6.3\n",
            "episode 4500 average score-6.4\n",
            "episode 4500 average score-6.5\n",
            "episode 4500 average score-6.6\n",
            "episode 4500 average score-6.7\n",
            "episode 4500 average score-6.9\n",
            "episode 4500 average score-7.0\n",
            "episode 4500 average score-7.2\n",
            "episode 4500 average score-7.4\n",
            "episode 4500 average score-7.6\n",
            "episode 4500 average score-7.8\n",
            "episode 4500 average score-8.0\n",
            "episode 4500 average score-8.3\n",
            "episode 4500 average score-8.5\n",
            "episode 4500 average score-8.7\n",
            "episode 4500 average score-9.0\n",
            "episode 4500 average score-9.2\n",
            "episode 4500 average score-9.5\n",
            "episode 4500 average score-9.7\n",
            "episode 4500 average score-10.0\n",
            "episode 4500 average score-10.2\n",
            "episode 4500 average score-10.5\n",
            "episode 4500 average score-10.7\n",
            "episode 4500 average score-11.0\n",
            "episode 4500 average score-11.2\n",
            "episode 4500 average score-11.5\n",
            "episode 5000 average score-7.1\n",
            "episode 5000 average score-6.9\n",
            "episode 5000 average score-6.7\n",
            "episode 5000 average score-6.5\n",
            "episode 5000 average score-6.3\n",
            "episode 5000 average score-6.1\n",
            "episode 5000 average score-5.9\n",
            "episode 5000 average score-5.7\n",
            "episode 5000 average score-5.5\n",
            "episode 5000 average score-5.2\n",
            "episode 5000 average score-5.0\n",
            "episode 5000 average score-4.8\n",
            "episode 5000 average score-4.6\n",
            "episode 5000 average score-4.4\n",
            "episode 5000 average score-4.1\n",
            "episode 5000 average score-3.9\n",
            "episode 5000 average score-3.7\n",
            "episode 5000 average score-3.5\n",
            "episode 5000 average score-3.2\n",
            "episode 5000 average score-3.2\n",
            "episode 5000 average score-3.2\n",
            "episode 5000 average score-3.2\n",
            "episode 5000 average score-3.1\n",
            "episode 5000 average score-3.0\n",
            "episode 5000 average score-3.0\n",
            "episode 5000 average score-2.9\n",
            "episode 5000 average score-2.8\n",
            "episode 5500 average score-5.2\n",
            "episode 5500 average score-5.1\n",
            "episode 5500 average score-5.1\n",
            "episode 5500 average score-5.0\n",
            "episode 5500 average score-4.9\n",
            "episode 5500 average score-4.9\n",
            "episode 5500 average score-4.8\n",
            "episode 5500 average score-4.8\n",
            "episode 5500 average score-4.7\n",
            "episode 5500 average score-4.7\n",
            "episode 5500 average score-4.6\n",
            "episode 5500 average score-4.6\n",
            "episode 5500 average score-4.5\n",
            "episode 5500 average score-4.5\n",
            "episode 5500 average score-4.4\n",
            "episode 5500 average score-4.4\n",
            "episode 5500 average score-4.3\n",
            "episode 5500 average score-4.3\n",
            "episode 5500 average score-4.2\n",
            "episode 5500 average score-4.2\n",
            "episode 5500 average score-4.3\n",
            "episode 5500 average score-4.3\n",
            "episode 5500 average score-4.3\n",
            "episode 5500 average score-4.3\n",
            "episode 5500 average score-4.3\n",
            "episode 5500 average score-4.3\n",
            "episode 5500 average score-4.4\n",
            "episode 6000 average score-4.9\n",
            "episode 6000 average score-4.9\n",
            "episode 6000 average score-4.8\n",
            "episode 6000 average score-4.7\n",
            "episode 6000 average score-4.6\n",
            "episode 6000 average score-4.5\n",
            "episode 6000 average score-4.4\n",
            "episode 6000 average score-4.3\n",
            "episode 6000 average score-4.3\n",
            "episode 6000 average score-4.2\n",
            "episode 6000 average score-4.1\n",
            "episode 6000 average score-4.0\n",
            "episode 6000 average score-3.9\n",
            "episode 6000 average score-3.8\n",
            "episode 6000 average score-3.7\n",
            "episode 6000 average score-3.6\n",
            "episode 6000 average score-3.5\n",
            "episode 6000 average score-3.5\n",
            "episode 6000 average score-3.4\n",
            "episode 6000 average score-3.4\n",
            "episode 6000 average score-3.4\n",
            "episode 6000 average score-3.4\n",
            "episode 6000 average score-3.4\n",
            "episode 6000 average score-3.4\n",
            "episode 6000 average score-3.4\n",
            "episode 6000 average score-3.4\n",
            "episode 6000 average score-3.4\n",
            "episode 6500 average score-4.9\n",
            "episode 6500 average score-4.8\n",
            "episode 6500 average score-4.8\n",
            "episode 6500 average score-4.7\n",
            "episode 6500 average score-4.6\n",
            "episode 6500 average score-4.6\n",
            "episode 6500 average score-4.5\n",
            "episode 6500 average score-4.4\n",
            "episode 6500 average score-4.4\n",
            "episode 6500 average score-4.3\n",
            "episode 6500 average score-4.2\n",
            "episode 6500 average score-4.2\n",
            "episode 6500 average score-4.1\n",
            "episode 6500 average score-4.1\n",
            "episode 6500 average score-4.0\n",
            "episode 6500 average score-3.9\n",
            "episode 6500 average score-3.9\n",
            "episode 6500 average score-3.8\n",
            "episode 6500 average score-3.7\n",
            "episode 6500 average score-3.8\n",
            "episode 6500 average score-3.8\n",
            "episode 6500 average score-3.8\n",
            "episode 6500 average score-3.8\n",
            "episode 6500 average score-3.9\n",
            "episode 6500 average score-3.9\n",
            "episode 6500 average score-3.9\n",
            "episode 6500 average score-3.9\n",
            "episode 7000 average score-6.4\n",
            "episode 7000 average score-6.3\n",
            "episode 7000 average score-6.3\n",
            "episode 7000 average score-6.2\n",
            "episode 7000 average score-6.2\n",
            "episode 7000 average score-6.1\n",
            "episode 7000 average score-6.1\n",
            "episode 7000 average score-6.0\n",
            "episode 7000 average score-6.0\n",
            "episode 7000 average score-5.9\n",
            "episode 7000 average score-5.9\n",
            "episode 7000 average score-5.9\n",
            "episode 7000 average score-5.8\n",
            "episode 7000 average score-5.8\n",
            "episode 7000 average score-5.7\n",
            "episode 7000 average score-5.7\n",
            "episode 7000 average score-5.7\n",
            "episode 7000 average score-5.6\n",
            "episode 7000 average score-5.6\n",
            "episode 7000 average score-5.6\n",
            "episode 7000 average score-5.6\n",
            "episode 7000 average score-5.7\n",
            "episode 7000 average score-5.7\n",
            "episode 7000 average score-5.7\n",
            "episode 7000 average score-5.8\n",
            "episode 7000 average score-5.8\n",
            "episode 7000 average score-5.8\n",
            "episode 7500 average score-6.9\n",
            "episode 7500 average score-7.0\n",
            "episode 7500 average score-7.0\n",
            "episode 7500 average score-7.0\n",
            "episode 7500 average score-7.0\n",
            "episode 7500 average score-7.0\n",
            "episode 7500 average score-7.0\n",
            "episode 7500 average score-7.1\n",
            "episode 7500 average score-7.1\n",
            "episode 7500 average score-7.1\n",
            "episode 7500 average score-7.1\n",
            "episode 7500 average score-7.2\n",
            "episode 7500 average score-7.2\n",
            "episode 7500 average score-7.2\n",
            "episode 7500 average score-7.2\n",
            "episode 7500 average score-7.3\n",
            "episode 7500 average score-7.3\n",
            "episode 7500 average score-7.3\n",
            "episode 7500 average score-7.3\n",
            "episode 7500 average score-7.4\n",
            "episode 7500 average score-7.4\n",
            "episode 7500 average score-7.4\n",
            "episode 7500 average score-7.4\n",
            "episode 7500 average score-7.4\n",
            "episode 7500 average score-7.4\n",
            "episode 7500 average score-7.3\n",
            "episode 7500 average score-7.3\n",
            "episode 8000 average score-7.6\n",
            "episode 8000 average score-7.5\n",
            "episode 8000 average score-7.4\n",
            "episode 8000 average score-7.3\n",
            "episode 8000 average score-7.2\n",
            "episode 8000 average score-7.1\n",
            "episode 8000 average score-7.0\n",
            "episode 8000 average score-6.9\n",
            "episode 8000 average score-6.8\n",
            "episode 8000 average score-6.8\n",
            "episode 8000 average score-6.7\n",
            "episode 8000 average score-6.6\n",
            "episode 8000 average score-6.5\n",
            "episode 8000 average score-6.4\n",
            "episode 8000 average score-6.3\n",
            "episode 8000 average score-6.2\n",
            "episode 8000 average score-6.1\n",
            "episode 8000 average score-6.0\n",
            "episode 8000 average score-5.9\n",
            "episode 8000 average score-5.9\n",
            "episode 8000 average score-5.9\n",
            "episode 8000 average score-5.8\n",
            "episode 8000 average score-5.8\n",
            "episode 8000 average score-5.7\n",
            "episode 8000 average score-5.7\n",
            "episode 8000 average score-5.6\n",
            "episode 8000 average score-5.5\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.4\n",
            "episode 8500 average score-10.5\n",
            "episode 8500 average score-10.5\n",
            "episode 8500 average score-10.5\n",
            "episode 8500 average score-10.5\n",
            "episode 8500 average score-10.5\n",
            "episode 8500 average score-10.5\n",
            "episode 8500 average score-10.6\n",
            "episode 8500 average score-10.6\n",
            "episode 8500 average score-10.6\n",
            "episode 8500 average score-10.7\n",
            "episode 8500 average score-10.7\n",
            "episode 8500 average score-10.8\n",
            "episode 8500 average score-10.9\n",
            "episode 8500 average score-10.9\n",
            "episode 8500 average score-11.0\n",
            "episode 8500 average score-11.0\n",
            "episode 9000 average score-5.2\n",
            "episode 9000 average score-5.1\n",
            "episode 9000 average score-5.1\n",
            "episode 9000 average score-5.0\n",
            "episode 9000 average score-5.0\n",
            "episode 9000 average score-5.0\n",
            "episode 9000 average score-4.9\n",
            "episode 9000 average score-4.9\n",
            "episode 9000 average score-4.8\n",
            "episode 9000 average score-4.8\n",
            "episode 9000 average score-4.8\n",
            "episode 9000 average score-4.7\n",
            "episode 9000 average score-4.7\n",
            "episode 9000 average score-4.7\n",
            "episode 9000 average score-4.6\n",
            "episode 9000 average score-4.6\n",
            "episode 9000 average score-4.5\n",
            "episode 9000 average score-4.5\n",
            "episode 9000 average score-4.5\n",
            "episode 9000 average score-4.5\n",
            "episode 9000 average score-4.5\n",
            "episode 9000 average score-4.5\n",
            "episode 9000 average score-4.4\n",
            "episode 9000 average score-4.4\n",
            "episode 9000 average score-4.4\n",
            "episode 9000 average score-4.4\n",
            "episode 9000 average score-4.4\n",
            "episode 9500 average score-9.2\n",
            "episode 9500 average score-9.1\n",
            "episode 9500 average score-9.0\n",
            "episode 9500 average score-8.8\n",
            "episode 9500 average score-8.7\n",
            "episode 9500 average score-8.6\n",
            "episode 9500 average score-8.5\n",
            "episode 9500 average score-8.3\n",
            "episode 9500 average score-8.2\n",
            "episode 9500 average score-8.1\n",
            "episode 9500 average score-7.9\n",
            "episode 9500 average score-7.8\n",
            "episode 9500 average score-7.6\n",
            "episode 9500 average score-7.5\n",
            "episode 9500 average score-7.4\n",
            "episode 9500 average score-7.2\n",
            "episode 9500 average score-7.1\n",
            "episode 9500 average score-7.0\n",
            "episode 9500 average score-6.8\n",
            "episode 9500 average score-6.8\n",
            "episode 9500 average score-6.8\n",
            "episode 9500 average score-6.7\n",
            "episode 9500 average score-6.7\n",
            "episode 9500 average score-6.6\n",
            "episode 9500 average score-6.6\n",
            "episode 9500 average score-6.5\n",
            "episode 9500 average score-6.4\n",
            "episode 10000 average score-5.3\n",
            "episode 10000 average score-5.1\n",
            "episode 10000 average score-4.9\n",
            "episode 10000 average score-4.8\n",
            "episode 10000 average score-4.6\n",
            "episode 10000 average score-4.4\n",
            "episode 10000 average score-4.3\n",
            "episode 10000 average score-4.1\n",
            "episode 10000 average score-3.9\n",
            "episode 10000 average score-3.8\n",
            "episode 10000 average score-3.6\n",
            "episode 10000 average score-3.4\n",
            "episode 10000 average score-3.3\n",
            "episode 10000 average score-3.1\n",
            "episode 10000 average score-2.9\n",
            "episode 10000 average score-2.7\n",
            "episode 10000 average score-2.6\n",
            "episode 10000 average score-2.4\n",
            "episode 10000 average score-2.2\n",
            "episode 10000 average score-2.2\n",
            "episode 10000 average score-2.2\n",
            "episode 10000 average score-2.2\n",
            "episode 10000 average score-2.2\n",
            "episode 10000 average score-2.2\n",
            "episode 10000 average score-2.2\n",
            "episode 10000 average score-2.3\n",
            "episode 10000 average score-2.3\n",
            "episode 10500 average score-2.4\n",
            "episode 10500 average score-2.4\n",
            "episode 10500 average score-2.3\n",
            "episode 10500 average score-2.3\n",
            "episode 10500 average score-2.3\n",
            "episode 10500 average score-2.3\n",
            "episode 10500 average score-2.3\n",
            "episode 10500 average score-2.3\n",
            "episode 10500 average score-2.3\n",
            "episode 10500 average score-2.3\n",
            "episode 10500 average score-2.2\n",
            "episode 10500 average score-2.2\n",
            "episode 10500 average score-2.2\n",
            "episode 10500 average score-2.2\n",
            "episode 10500 average score-2.2\n",
            "episode 10500 average score-2.2\n",
            "episode 10500 average score-2.2\n",
            "episode 10500 average score-2.2\n",
            "episode 10500 average score-2.2\n",
            "episode 10500 average score-2.1\n",
            "episode 10500 average score-2.1\n",
            "episode 10500 average score-2.1\n",
            "episode 10500 average score-2.1\n",
            "episode 10500 average score-2.1\n",
            "episode 10500 average score-2.1\n",
            "episode 10500 average score-2.1\n",
            "episode 10500 average score-2.1\n",
            "episode 11000 average score-9.2\n",
            "episode 11000 average score-9.0\n",
            "episode 11000 average score-8.7\n",
            "episode 11000 average score-8.4\n",
            "episode 11000 average score-8.1\n",
            "episode 11000 average score-7.8\n",
            "episode 11000 average score-7.5\n",
            "episode 11000 average score-7.2\n",
            "episode 11000 average score-6.9\n",
            "episode 11000 average score-6.6\n",
            "episode 11000 average score-6.3\n",
            "episode 11000 average score-6.0\n",
            "episode 11000 average score-5.7\n",
            "episode 11000 average score-5.4\n",
            "episode 11000 average score-5.1\n",
            "episode 11000 average score-4.8\n",
            "episode 11000 average score-4.5\n",
            "episode 11000 average score-4.2\n",
            "episode 11000 average score-3.9\n",
            "episode 11000 average score-3.9\n",
            "episode 11000 average score-4.0\n",
            "episode 11000 average score-4.0\n",
            "episode 11000 average score-4.0\n",
            "episode 11000 average score-4.0\n",
            "episode 11000 average score-4.0\n",
            "episode 11000 average score-4.0\n",
            "episode 11000 average score-4.1\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.4\n",
            "episode 11500 average score-5.5\n",
            "episode 11500 average score-5.5\n",
            "episode 11500 average score-5.5\n",
            "episode 11500 average score-5.6\n",
            "episode 11500 average score-5.6\n",
            "episode 11500 average score-5.6\n",
            "episode 11500 average score-5.7\n",
            "episode 11500 average score-5.7\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.0\n",
            "episode 12000 average score-7.0\n",
            "episode 12000 average score-7.0\n",
            "episode 12000 average score-7.0\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n",
            "episode 12000 average score-7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rzba6VX9-pEz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}